HOST: Good Morning! And welcome to Weekly Tech Round-up! I'm Arjav. Today is February 20th, 2026. On this day in history, back in 1986, the Internet Engineering Task Force, or IETF, was officially formed. This group has been fundamental in developing and maintaining the internet standards that allow our digital world to function every single day. From that foundational work to today's cutting-edge innovations, we're diving deep into the tech landscape. Joining me as always is our lead tech reporter, Arohi, to break down the most impactful stories from Ars Technica, Hacker News, TechCrunch, and many other leading sources. Arohi, it's great to have you back!

REPORTER: Thanks, Arjav, always a pleasure to be here. We have a packed agenda today, especially with some major movements from the industry giants in AI.

HOST: Absolutely. Let's kick things off with a major player: Apple. It seems they're not just watching the AI hardware space heat up; they're getting right into the kitchen, reportedly cooking up a trio of AI wearables. What can you tell us about this?

REPORTER: That's right. Apple, traditionally cautious with new product categories, is reportedly accelerating its AI hardware initiatives. Sources indicate they have multiple smart products in development that integrate advanced AI capabilities directly into wearable form factors. While specific details are still under wraps, the speculation points towards devices that go beyond current smartwatches and headphones, offering more proactive and context-aware assistance, leveraging AI at the edge for real-time processing. This is a significant move as they look to define the next generation of personal tech beyond the iPhone.

HOST: Fascinating. So, more than just a Siri upgrade on our wrist. Meanwhile, Microsoft has been grappling with the tricky balance of integrating AI while maintaining trust and security. They've introduced a new plan to combat online AI deception, but have also had a few high-profile stumbles, including a Copilot bug exposing confidential emails and even a gaffe involving training AI on pirated books. It sounds like a complex week for them.

REPORTER: It certainly has been. Microsoft is tackling the growing challenge of AI-enabled deception online with a new initiative focused on proving what's real versus what's AI. This comes as manipulated content, from deepfakes to subtle AI-generated text, permeates our digital lives. They aim to provide tools and frameworks to help users and organizations identify AI-generated content.
However, this push for trustworthiness was immediately tested. The company admitted to a bug in its Copilot AI chatbot that inadvertently exposed paying customers' confidential emails, summarizing them and bypassing data protection policies. This was a serious lapse, leading to immediate fixes and a review of their security protocols.
And on a different, but equally concerning note, Microsoft had to delete a blog post that advised users on how to train large language models using pirated Harry Potter books, which were "mistakenly" marked as public domain in their internal documentation. It highlights the vast and often unvetted data sources AI models are trained on, and the potential for copyright infringement.

HOST: Wow, a big week indeed for Microsoft, navigating both the promise and pitfalls of AI implementation. It underscores the critical need for robust safeguards and ethical considerations.

HOST: Moving on to a trend we've been tracking closely: agentic AI. It feels like these autonomous systems are becoming a cornerstone for enterprise solutions. Infosys has just partnered with Anthropic, a major player in this space, to build what they call "enterprise-grade AI agents." What's the strategy here?

REPORTER: This partnership between Infosys and Anthropic is a significant one. Infosys plans to integrate Anthropic's Claude models into its Topaz AI platform. The goal is to develop highly sophisticated, "agentic" systems designed specifically for enterprise environments. These agents will be capable of understanding complex tasks, reasoning, planning, and executing actions autonomously within business workflows. The emphasis is on creating reliable, secure, and scalable AI agents that can handle critical business processes, a clear response to the demand for more advanced automation beyond simple chatbots.

HOST: And we're already seeing these agentic systems being operationalized. I understand there's a good example in retail. How is agentic AI working there, and what does it take to implement it effectively?

REPORTER: In retail, agentic AI is being applied across the entire software development lifecycle, from validating requirements to generating test cases and even automating deployment. Prasad Banala, a director of software engineering at a large US retail organization, highlighted how his team uses AI to streamline operations. The key takeaway is that making agentic AI work requires not just the technology, but also a robust framework for oversight, continuous learning, and human-in-the-loop validation. It’s about creating systems that can perform complex tasks, but also have mechanisms for course correction and adherence to business rules, ensuring they don't go "off-script.".

HOST: "Off-script" is a good point, especially considering some of the recent concerns. We've seen projects like "Cord" aiming to coordinate trees of AI agents, which sounds like a way to manage complexity. But then there's also "OpenClaw," which has reportedly sparked security fears due to its unpredictability. Can you elaborate on these two contrasting developments?

REPORTER: Absolutely. Cord represents a step towards managing the inherent complexity of multiple AI agents working together. It's a framework designed to coordinate "trees of AI agents," allowing for more structured and hierarchical problem-solving. This approach aims to bring order and predictability to agentic systems by breaking down large tasks into smaller, manageable ones handled by specialized agents, all while maintaining overall control.
On the flip side, OpenClaw is a viral agentic AI tool that has garnered attention for its high capability, but also for being wildly unpredictable. This unpredictability has led major AI firms, including Meta, to restrict its use due to significant security fears. The concern is that while OpenClaw can perform impressively, its autonomous and sometimes uninterpretable behavior poses risks in sensitive environments, raising questions about control, safety, and accountability when AI agents operate without clear boundaries. It’s a stark illustration of the double-edged sword of highly autonomous AI.

HOST: So, on one hand, efforts to bring structure to multi-agent systems, and on the other, a powerful but potentially rogue AI. A clear indication of the innovation and the challenges within the agentic AI space.

HOST: Let's shift our focus to open-source programs. AI coding tools were once hailed as a boon for developers, but it seems they're proving to be a mixed blessing, perhaps even leading to a flood of "bad code." What's happening there?

REPORTER: That's the sentiment among many open-source maintainers. While AI coding tools can significantly accelerate the generation of new features and code snippets, they've also enabled a flood of lower-quality or unoptimized code. This "bad code" can threaten to overwhelm projects because while it's easier to generate, it's just as hard, if not harder, to maintain, debug, and secure. The problem lies in the sheer volume and the often superficial understanding AI tools have of complex project architectures or specific coding standards. It's creating a maintenance burden that could slow down, rather than speed up, long-term open-source development.

HOST: That's a critical point for the developer community. However, in India, an AI lab named Sarvam is making a significant bet on the viability of open-source AI with a new lineup of models. This sounds like a counter-narrative, or at least a different approach.

REPORTER: Indeed, it is. Sarvam, an Indian AI lab, is making a major statement about the potential of open-source AI with their new models. Their lineup includes large parameter models, specifically 30-billion and 105-billion parameter models, alongside specialized text-to-speech, speech-to-text, and vision models designed to parse documents. This move is a strong endorsement of open-source development, aiming to provide powerful, accessible AI tools that can be customized and deployed by a wider community. It also highlights India's growing ambition in the global AI landscape, emphasizing local innovation and the belief that open-source models can foster widespread adoption and application, especially in diverse linguistic and cultural contexts.

HOST: A fascinating contrast – the challenges of managing AI-generated code versus the potential for open-source AI to democratize access and innovation.

HOST: Moving over to Google, their new Gemini Pro model is once again making waves with record benchmark scores. What does this mean for the capabilities of Google's LLMs?

REPORTER: Google's latest Gemini 3.1 Pro model is indeed setting new benchmarks, indicating a significant leap in capabilities. This new iteration promises an LLM capable of handling even more complex forms of work, including intricate reasoning, multi-modal understanding, and nuanced problem-solving. These record scores suggest Google is pushing the boundaries of what its large language models can achieve, aiming for greater efficiency, accuracy, and versatility across a wide range of applications, from advanced data analysis to highly creative tasks.

HOST: Impressive. And on the enterprise front, Google Cloud's VP recently discussed what startups need to do when their "check engine light" comes on, especially regarding infrastructure choices. How does this tie into the broader AI landscape for startups?

REPORTER: This is a crucial point for the startup ecosystem. Google Cloud's VP explained that while cloud credits, GPU access, and foundation models make it easier for startups to get off the ground with AI, early infrastructure choices can have unforeseen consequences down the line. Startups are pressured to move fast, use AI, and show traction, often facing tighter funding and rising infrastructure costs. The "check engine light" analogy refers to those moments when early technical decisions lead to scalability issues, cost overruns, or performance bottlenecks. The advice emphasizes the need for thoughtful, scalable architectural planning from the outset, especially when building AI-centric applications, to avoid costly re-architecting later.

HOST: So, building smart from the beginning is key, especially with the rapid evolution of AI technology.

HOST: Let's broaden our scope and look at some truly diverse applications of AI. From predicting the future to hunting for antibiotics, it seems AI's potential is only just beginning to be explored. Let's start with this idea of "robots who predict the future." How is AI enhancing our forecasting abilities?

REPORTER: The concept of "robots who predict the future" explores how AI is fundamentally changing our ability to forecast. Humans have always tried to predict the future based on past experience or cause-and-effect logic. AI significantly amplifies this by analyzing vast datasets, identifying complex patterns, and running simulations at speeds and scales impossible for humans. This ranges from predicting market trends and climate patterns to even social dynamics, offering a more data-driven and potentially more accurate lens through which to anticipate future events. It’s about augmenting our innate human forecasting with computational power.

HOST: And from predicting the future to proactively shaping it in the medical field – there's a scientist using AI to hunt for antibiotics just about everywhere. This sounds like a groundbreaking approach to a critical global health challenge.

REPORTER: It absolutely is. César de la Fuente, a scientist, is leveraging AI in a truly innovative way to combat antimicrobial resistance, a problem he identified as one of the world's biggest. His team is using AI to screen vast numbers of natural compounds and synthetic molecules, even from unexpected sources, to discover new antibiotics. Traditional drug discovery is slow and expensive, but AI can rapidly sift through chemical spaces, predict molecular properties, and identify potential candidates much faster. This AI-driven approach offers a beacon of hope in the race against increasingly resistant superbugs.

HOST: Truly remarkable. AI also has the potential to democratize creativity, but also poses new challenges. For indie filmmakers, AI coding tools are promising faster and cheaper production, yet there's a concern about increased loneliness and a deluge of low-effort content. What's the balance here?

REPORTER: This is a complex discussion for the creator economy. AI certainly expands access to filmmaking for resource-constrained creators. Tools can automate tasks like visual effects, editing, even scriptwriting assistance, drastically cutting down production time and costs. However, the concern is that as efficiency becomes the industry's north star, creativity risks being overwhelmed by a deluge of low-effort, AI-generated content. There’s also the potential for increased isolation, as AI tools might reduce the need for collaborative human teams, leading to a "lonelier" creative process. It's a trade-off between accessibility and the unique human touch.

HOST: A very pertinent challenge. On the manufacturing front, Freeform recently raised 67 million dollars in Series B funding to scale up laser AI manufacturing. This sounds like an industrial revolution in the making.

REPORTER: It certainly does. Freeform is at the forefront of what they call "laser AI manufacturing." Their significant Series B funding will enable them to scale up their operations. What makes them unique is their deep integration of AI directly into the manufacturing process, specifically using H200 clusters in their data centers on-site. This allows for real-time optimization, quality control, and adaptive manufacturing processes using AI-driven laser systems. It promises unprecedented precision, speed, and efficiency in producing complex parts, effectively bridging the gap between advanced AI and high-precision physical manufacturing.

HOST: That's incredible. And connecting all these AI-driven endeavors, especially the growing demand for processing power, SpaceX veterans are now raising 50 million dollars for data center links. What's the focus of Mesh, their new venture?

REPORTER: Mesh, founded by SpaceX veterans, is addressing a critical bottleneck in the AI infrastructure: data center connectivity. They've raised 50 million dollars in Series A funding to mass-produce optical transceivers specifically designed for AI data centers. As AI models grow larger and demand more data transfer between GPUs and servers, the need for high-bandwidth, low-latency interconnections becomes paramount. Mesh aims to provide these essential links, ensuring that the physical hardware can keep up with the insatiable data demands of modern AI, preventing data transfer from becoming the next major hurdle for AI scaling.

HOST: So, the infrastructure beneath the AI revolution is getting a major boost as well.

HOST: The business of AI is booming, with startups emerging at an incredible pace. We've seen a trend, dubbed the "OpenAI mafia," referring to the numerous startups founded by alumni of OpenAI. What does this tell us about the ecosystem?

REPORTER: The term "OpenAI mafia" refers to the significant number of startups launched by former OpenAI employees. Since OpenAI's inception a decade ago, many talented individuals have left to start their own ventures. Some, like Anthropic, have become direct rivals, raising billions and developing their own foundational models. Others have managed to secure massive investor interest, often raising hundreds of millions or even billions of dollars before even launching a product, purely on the strength of their founders' pedigree and vision. This phenomenon highlights a vibrant, highly competitive, and incredibly well-funded ecosystem emerging directly from the intellectual capital cultivated at pioneering AI labs.

HOST: A testament to the entrepreneurial spirit within the AI space. And within this busy landscape, the "enterprise AI land grab is on." Glean is positioning itself as the "layer beneath the interface." What exactly does that mean, and what's their strategy?

REPORTER: Glean, led by CEO Arvind Jain, is making a strategic pivot. Initially an enterprise search tool, it's now evolving into a middleware layer for enterprise AI. This means instead of just providing a user-facing search interface, Glean aims to be the foundational intelligence platform that connects and orchestrates various AI applications and data sources within an enterprise. They want to be the invisible infrastructure that powers intelligent assistants, automated workflows, and data insights across different departments, enabling businesses to deploy and manage AI agents and services more effectively. It's about building the plumbing for the AI-powered enterprise.

HOST: Building the intelligent infrastructure. That makes sense. Despite all this innovation, there's a recurring debate about AI replacing human roles. However, some startup CEOs believe AI tools will replace tasks, not workers. What's their perspective?

REPORTER: That's the view from CEOs like those at Read AI and Lucidya, who spoke at Web Summit Qatar. They argue that while AI tools are becoming incredibly sophisticated, their primary function will be to augment human capabilities by automating tedious, repetitive, or data-intensive tasks. For example, AI can summarize meetings, analyze customer support interactions, or generate initial drafts, freeing up human workers to focus on more complex problem-solving, creative endeavors, and interpersonal communication. The sentiment is that AI will redefine job descriptions, making humans more efficient and strategic, rather than making them obsolete.

HOST: An optimistic outlook on the future of work. And speaking of optimistic, some companies are taking a truly unconventional approach. A startup called "Flapping Airplanes" says they want to "try really radically different things" regarding the future of AI. What kind of tradeoffs are they exploring?

REPORTER: Flapping Airplanes, while somewhat enigmatic in their exact offerings, represent a segment of the AI industry that's deliberately pushing against conventional approaches. Their philosophy centers on exploring "a different set of tradeoffs." This could mean prioritizing alternative computing paradigms, developing novel AI architectures that don't rely solely on massive datasets, or even exploring ethical frameworks that challenge mainstream AI development. They're hinting at moving beyond incremental improvements to existing models, aiming for breakthroughs by questioning fundamental assumptions about how AI should be built and deployed. It's a venture into the truly experimental side of AI.

HOST: Very intriguing. It reminds me of the broader conversation about the AI landscape. We've heard a lot of hype, but some suggest we might be entering a "great AI hype correction of 2025." What's this correction about, and what does it imply for our expectations?

REPORTER: This "great AI hype correction" refers to a potential re-evaluation of expectations following the intense excitement around AI in recent years. The premise is that many top AI companies made promises they couldn't keep, leading to inflated valuations and unrealistic timelines for widespread, transformative AI adoption. The correction suggests that 2025 might have been a year of reckoning, where the industry and investors began to readjust their expectations, recognizing the long and complex road ahead for truly robust, scalable, and ethically sound AI solutions. It's a move towards a more realistic understanding of AI's current limitations and the significant challenges that remain.

HOST: A healthy dose of realism, perhaps. Shifting gears slightly, the creator economy is also rapidly evolving, and ad revenue alone isn't cutting it. India's AI ambitions are playing a role here too. How are these two interconnected?

REPORTER: The creator economy is indeed diversifying beyond ad revenue, with creators launching product lines and building business empires. Think of someone like MrBeast, whose chocolate business now outearns his media arm. This entrepreneurial shift is driven by a need for more stable and direct revenue streams. India's AI ambitions connect here in several ways: AI tools can empower creators with more efficient content production, personalized marketing, and even new monetization models like AI-generated merchandise or unique digital experiences. Furthermore, India's own burgeoning startup scene and focus on localized AI solutions are creating new opportunities for creators within that market, driving innovation in how content is produced, distributed, and monetized globally.

HOST: A dynamic intersection of creativity, business, and technology. And for those looking to get into the startup world, a16z's Speedrun accelerator program is notoriously competitive. Any tips on standing out for that program?

REPORTER: For aspiring founders aiming for a16z's super-competitive Speedrun accelerator, partner Joshua Lu shared some key advice. Beyond a strong team and a compelling idea, he emphasized demonstrating deep domain expertise and a unique insight into the problem you're solving. They look for founders who aren't just jumping on a trend but have a profound understanding of a market gap or technological frontier. Showing early traction, even if small, and articulating a clear vision for how your solution leverages cutting-edge technology, particularly AI, in an innovative way can significantly boost your chances. It’s about being truly exceptional and forward-thinking.

HOST: Excellent advice for any aspiring entrepreneur. Finally, just a quick note on a non-AI-centric but important tech development: Bluesky has launched private messaging.

REPORTER: Yes, Bluesky, the decentralized social network, has expanded its capabilities by integrating a private messenger natively within its app. This is done through a partnership with a startup called Germ, which provides end-to-end encrypted messaging. It’s a significant step for Bluesky in offering a more comprehensive social experience, addressing a key user demand for private communication within its ecosystem, while ensuring strong privacy measures through encryption.

HOST: That's great news for Bluesky users. And before we wrap up, Metriport, a Y Combinator alum, is hiring a security engineer to harden healthcare infrastructure. This highlights the ongoing need for robust cybersecurity in all tech sectors, especially sensitive ones like healthcare.

REPORTER: Absolutely. Metriport, focused on healthcare infrastructure, is actively seeking a security engineer. This recruitment underscores the critical importance of cybersecurity in the health tech space. With the sensitive nature of patient data and the increasing sophistication of cyber threats, hardening healthcare infrastructure against breaches and vulnerabilities is paramount. It reflects a broader industry trend where security isn't an afterthought but a foundational element, especially as AI and other advanced technologies become more integrated into medical systems.

HOST: Arohi, what an incredible dive into the latest in tech! From Apple's new wearables to the intricacies of agentic AI and the evolving landscape of open-source development, it's clear innovation is moving at warp speed. Thank you for your expert insights today.

REPORTER: My pleasure, Arjav. Always a lot to unpack in the tech world.

HOST: And before we sign off, here's a fun fact to leave you with: Did you know the term "robot" originates from a 1920 Czech play titled "R.U.R." or "Rossum's Universal Robots"? In the play, "robota" means "forced labor" or "drudgery," which is quite a contrast to our current vision of intelligent, autonomous AI systems. It just goes to show how far our imaginations, and technology, have come in just over a century.

HOST: That's all the time we have for today's Weekly Tech Round-up. We appreciate you tuning in. For all the latest headlines and deeper dives, keep an eye on Ars Technica, Hacker News, TechCrunch, and our own podcast page. I'm Arjav, and on behalf of Arohi and our entire team, thank you for listening. We'll be back next week with more of the biggest stories shaping our digital world. Have a fantastic day!