HOST: Good morning! And welcome to Weekly Tech Round-up! I'm Arjav.

REPORTER: And I'm Arohi, ready to dive into the latest in technology.

HOST: Absolutely. Before we jump into the week's headlines, let's take a quick look back. On this day, December 9th, in 1968, computer scientist Douglas Engelbart unveiled what is now famously known as "The Mother of All Demos." In a single, ninety-minute presentation, he introduced the world to the computer mouse, hypertext, video conferencing, teleconferencing, and networked collaboration â€“ essentially laying the groundwork for much of the digital world we navigate today. Truly foundational.

REPORTER: A powerful reminder of how far we've come.

HOST: Indeed. And speaking of groundbreaking developments, this week was a flurry of activity in the AI space, particularly from two of the biggest names in the industry. It seems the race for AI dominance is intensifying with new releases from both Google and OpenAI. What's the latest on this front?

REPORTER: You're right, the AI competition is heating up significantly. Google just launched its deepest AI research agent, based on Gemini 3 Pro, enabling developers to embed this powerful tool into their own applications. This move marks a significant step towards democratizing advanced AI research capabilities. What's particularly noteworthy is that this release came on the very same day OpenAI dropped GPT-5.2, signaling a clear escalation in the AI arms race.

HOST: So, OpenAI's GPT-5.2 is out. What can you tell us about that, especially in light of the "code red" alerts we've heard about?

REPORTER: OpenAI's GPT-5.2 release followed internal "code red" alerts, driven by perceived threats from Google's advancements. The company claims this new AI model not only tops Google's Gemini but also matches human performance on 70% of work tasks. This suggests a significant leap in AI's practical utility and problem-solving abilities. It's a clear statement from OpenAI about its position in the rapidly evolving AI landscape.

HOST: And how does this fit into the broader evolution of ChatGPT? It feels like we're getting updates constantly.

REPORTER: We are. ChatGPT continues its rapid evolution with a steady stream of product updates and releases throughout the year, making it a dynamic and ever-improving AI-powered chatbot. These continuous enhancements aim to refine its capabilities, improve user interaction, and expand its applications across various domains, showcasing a commitment to staying at the forefront of conversational AI.

HOST: Beyond just chat, I understand OpenAI is also quietly rolling out new "skills" for its models. What does that entail?

REPORTER: Yes, OpenAI is quietly adopting "skills" for its models, which are now available in ChatGPT and Codex CLI. These skills are essentially specialized modules or functions that allow the AI to perform more complex, multi-step tasks or interact with external tools and APIs more effectively. This development enhances the AI's versatility, enabling it to go beyond generating text and perform more sophisticated actions, marking a significant step towards more autonomous and capable AI agents.

HOST: That sounds like a powerful step forward. And speaking of powerful steps, OpenAI has also been leveraging AI to improve itself, particularly with its coding agent. That's quite a meta development, isn't it?

REPORTER: It absolutely is. OpenAI has developed an AI coding agent named Codex, and it's being used to improve the agent itself. The company stated that "the vast majority of Codex is built by Codex," which means the AI is writing and refining its own code. This self-improvement loop could accelerate AI development significantly, pushing the boundaries of what autonomous systems can achieve in software engineering and beyond.

HOST: That's fascinating, almost a bootstrap approach for AI. This kind of self-improvement has roots in advanced computational logic. I'm reminded of the foundational work in fields like proof assistants. Can you quickly touch on that history?

REPORTER: Briefly, proof assistants have a rich history spanning over 50 years. They are software tools that help users develop formal proofs by verifying the logical correctness of mathematical statements and software specifications. This field provides the rigorous framework for ensuring the reliability and validity of complex systems, including, in a conceptual way, the self-improving logic we see in AI agents today. It highlights the long-standing quest for verified intelligence.

HOST: From abstract logic to practical application, AI is making strides in very tangible ways. I heard about an AI co-pilot for prosthetic bionic hands. How does that work?

REPORTER: Scientists have indeed built an AI co-pilot for prosthetic bionic hands, a major advancement in assistive technology. The innovation focuses on managing each finger separately, which, with the right sensors, significantly eases control issues for users. This AI system translates neural signals or muscle movements into precise finger movements, offering a more intuitive and natural user experience than previous generations of prosthetics, greatly enhancing dexterity and functionality for amputees.

HOST: That's an incredible application of AI for human benefit. Another surprising application is AI's role in bringing old nuclear plants out of retirement. That sounds counter-intuitive at first.

REPORTER: It does, but AI is playing a crucial role in modernizing and optimizing the operations of older nuclear plants, making their revival more feasible and efficient. AI systems can analyze vast amounts of operational data, predict maintenance needs, optimize fuel usage, and enhance safety protocols. This allows these plants to run more efficiently and cost-effectively, extending their operational lifespan and contributing to energy grids that increasingly need stable, carbon-free power sources.

HOST: That's a powerful combination of old and new technology. Shifting gears to consumer tech, Google has made some significant advancements with its Translate service, particularly concerning real-time communication.

REPORTER: Yes, Google Translate has rolled out a major update that now allows for real-time translations directly in your headphones. This feature keeps each speaker's tone, emphasis, and cadence intact, making conversations much easier to follow and ensuring you can distinguish who's speaking. Initially launched for Google Pixel Buds, this expanded live translation capability is now available for all earbuds on Android devices, with iOS support coming in the months ahead. It's a huge step forward for seamless cross-lingual communication.

HOST: That's a truly game-changing feature for international travelers and global communication. However, Google also made headlines for a different kind of removal this week. What's the story behind Google removing Sci-Hub domains from U.S. search results?

REPORTER: Google has removed Sci-Hub domains from its U.S. search results. This action stems from a dated court order, highlighting ongoing legal battles between academic publishers and platforms like Sci-Hub, which provides free access to paywalled research papers. The removal impacts accessibility to scientific literature for many users in the U.S. and underscores the complex legal and ethical debates surrounding intellectual property and open access in academia.

HOST: A complex issue indeed. And speaking of critical issues, both Google and Apple had to roll out emergency security updates this week. What vulnerabilities were they addressing?

REPORTER: Both tech giants released urgent security updates after zero-day attacks were detected. Apple released patches for all its flagship devices, including iPhones, iPads, and Macs, to fix critical security flaws that were actively being exploited. Simultaneously, Google updated Chrome to remediate a vulnerability that was also being exploited in these attacks. These rapid responses are crucial for protecting user data and system integrity against sophisticated threats.

HOST: That's a serious reminder for everyone to keep their devices updated. Now, let's turn our attention to Apple specifically. The company faced a setback in court this week, didn't it?

REPORTER: Yes, Apple lost its appeal of a scathing contempt ruling in an iOS payments case. This decision is a significant blow for Apple, reinforcing previous judgments related to its App Store payment policies. While Epic Games, the plaintiff, celebrated what it sees as the end of the "Apple tax," critics warn that iOS developers are still apprehensive about potential "totally illegal" retaliation by Apple, suggesting the battle over app store control is far from over.

HOST: That legal fight definitely has long-term implications for developers. On a more personal note, we've seen a prominent story circulate about an individual's Apple ID being locked without recourse. What happened there?

REPORTER: A user shared a detailed account of having their Apple ID locked, leaving them with no means of recovery or recourse, despite numerous attempts to contact Apple support. This highly visible incident has highlighted significant concerns among users about account security, customer service efficacy, and the potential for a complete loss of access to digital assets tied to a single, unrecoverable account. It raises critical questions about user control and support within digital ecosystems.

HOST: That's a concerning situation for any user. On a lighter note for Apple users, there's a new iOS update addressing a customization feature.

REPORTER: Indeed. With iOS 26.2, Apple is now allowing users to roll back the "Liquid Glass" effect on their Lock Screen. Previously, the iPhone clock had a somewhat glassy, refractive appearance that wasn't to everyone's taste. This new software update gives users the option to revert to a more traditional or preferred clock aesthetic, offering more personalization for their device's interface.

HOST: Good to hear about user customization options. Moving to a broader topic, artificial intelligence and policy have been a big discussion this week, particularly concerning attempts to regulate AI at the state and federal levels.

REPORTER: That's right. Former President Trump has stepped in, attempting to block state AI laws himself after Congress decided not to pass federal legislation. He claims that various state laws force AI makers to embed what he calls "ideological bias" into their models. This intervention marks a significant move to centralize AI regulation and prevent a patchwork of state-level rules.

HOST: So, he signed an executive order to that effect? What are the implications of this "one rulebook" approach?

REPORTER: Yes, Trump signed an executive order targeting state AI laws and promising "one national rulebook" for artificial intelligence. The goal is to create a uniform regulatory environment, but critics warn that this approach could trigger extensive court battles and prolong uncertainty for AI startups while Congress continues to debate federal rules. The executive order seeks to eliminate state law obstruction of national AI policy, potentially setting the stage for a lengthy legal and political struggle over AI governance.

HOST: So, this is still a very fluid situation with potentially major consequences for the AI industry. Before we wrap up, there's another ethical concern related to AI that emerged this week, particularly concerning children's toys.

REPORTER: Absolutely, and it's a serious one. Chatbot-powered toys have been rebuked for discussing sexually explicit and dangerous topics with children. Consumer advocacy groups and tech safety experts have highlighted instances where these AI toys engaged in inappropriate conversations, raising alarms about the lack of sufficient safeguards. The consensus is clear: AI toys should not be capable of having sexually explicit conversations, period, underscoring an urgent need for stricter content filtering and ethical design in AI products for minors.

HOST: A very important discussion for parents and developers alike. Arohi, thank you for breaking down the week's top tech stories for us.

REPORTER: My pleasure, Arjav.

HOST: And here's a surprising tech fact for you to ponder: The term "robot" comes not from science fiction writers initially, but from a 1920 Czech play titled "R.U.R." or "Rossum's Universal Robots," where the word "robota" meant "forced labor" or "servitude." It certainly gives a different perspective on our modern AI creations! That's all for this week's Weekly Tech Round-up. Thanks for joining us. We'll see you next time!